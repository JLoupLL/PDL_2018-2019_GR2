Dataset Name;Brief description;Preprocessing;Instances;Format;Default Task;Created (updated);Reference;Creator;
Visual Genome;Images and their description;;108,000;images, text;Image captioning;2016;[61];R. Krishna et al.;
DAVIS: Densely Annotated VIdeo Segmentation 2017;150 video sequences containing 10459 frames with a total of 376 objects annotated.;Dataset released for the 2017 DAVIS Challenge with a dedicated workshop co-located with CVPR 2017. The videos contain several types of objects and humans with a high quality segmentation annotation.In each video sequence multiple instances are annotated.;10,459;Frames annotated;Video object segmentation;2017;[62];Pont-Tuset, J. et al.;
DAVIS: Densely Annotated VIdeo Segmentation 2016;50 video sequences containing 3455 frames with a total of 50 objects annotated.;Dataset released with the CVPR 2016 paper. The videos contain several types of objects and humans with a high quality segmentation annotation. In each video sequence a single instance is annotated.;3,455;Frames annotated;Video object segmentation;2016;[63];Perazzi, F. et al.;
T-LESS: An RGB-D Dataset for 6D Pose Estimation of Texture-less Objects;30 industry-relevant objects. 39K training and 10K test images from each of three sensors. Two types of 3D models for each object.;6D poses for all modeled objects in all images. Per-pixel labelling can be obtained by rendering of the object models at the ground truth poses.;49,000;RGB-D images, 3D object models;6D object pose estimation, object detection;2017;[64];T. Hodan et al.;
Berkeley 3-D Object Dataset;849 images taken in 75 different scenes. About 50 different object classes are labeled.;Object bounding boxes and labeling.;849;labeled images, text;Object recognition;2014;[65][66];A. Janoch et al.;
Berkeley Segmentation Data Set and Benchmarks 500 (BSDS500);500 natural images, explicitly separated into disjoint train, validation and test subsets + benchmarking code. Based on BSDS300.;Each image segmented by five different subjects on average.;500;Segmented images;Contour detection and hierarchical image segmentation;2011;[67];University of California, Berkeley;
Microsoft Common Objects in Context (COCO);complex everyday scenes of common objects in their natural context.;Object highlighting, labeling, and classification into 91 object types.;2,500,000;Labeled images, text;Object recognition;2015;[68][69];T. Lin et al.;
SUN Database;Very large scene and object recognition database.;Places and objects are labeled. Objects are segmented.;131,067;Images, text;Object recognition, scene recognition;2014;[70][71];J. Xiao et al.;
ImageNet;Labeled object image database, used in the ImageNet Large Scale Visual Recognition Challenge;Labeled objects, bounding boxes, descriptive words, SIFT features;14,197,122;Images, text;Object recognition, scene recognition;2009 (2014);[72][73][74];J. Deng et al.;
Open Images;A Large set of images listed as having CC BY 2.0 license with image-level labels and bounding boxes spanning thousands of classes.;Image-level labels, Bounding boxes;9,178,275;Images, text;Classification, Object recognition;2017;[75];;
TV News Channel Commercial Detection Dataset;TV commercials and news broadcasts.;Audio and video features extracted from still images.;129,685;Text;Clustering, classification;2015;[76][77];P. Guha et al.;
Statlog (Image Segmentation) Dataset;The instances were drawn randomly from a database of 7 outdoor images and hand-segmented to create a classification for every pixel.;Many features calculated.;2310;Text;Classification;1990;[78];University of Massachusetts;
Caltech 101;Pictures of objects.;Detailed object outlines marked.;9146;Images;Classification, object recognition.;2003;[79][80];F. Li et al.;
Caltech-256;Large dataset of images for object classification.;Images categorized and hand-sorted.;30,607;Images, Text;Classification, object detection;2007;[81][82];G. Griffin et al.;
SIFT10M Dataset;SIFT features of Caltech-256 dataset.;Extensive SIFT feature extraction.;11,164,866;Text;Classification, object detection;2016;[83];X. Fu et al.;
LabelMe;Annotated pictures of scenes.;Objects outlined.;187,240;Images, text;Classification, object detection;2005;[84];MIT Computer Science and Artificial Intelligence Laboratory;
Cityscapes Dataset;Stereo video sequences recorded in street scenes, with pixel-level annotations. Metadata also included.;Pixel-level segmentation and labeling;25,000;Images, text;Classification, object detection;2016;[85];Daimler AG et al.;
PASCAL VOC Dataset;Large number of images for classification tasks.;Labeling, bounding box included;500,000;Images, text;Classification, object detection;2010;[86][87];M. Everingham et al.;
CIFAR-10 Dataset;Many small, low-resolution, images of 10 classes of objects.;Classes labelled, training set splits created.;60,000;Images;Classification;2009;[73][88];A. Krizhevsky et al.;
CIFAR-100 Dataset;Like CIFAR-10, above, but 100 classes of objects are given.;Classes labelled, training set splits created.;60,000;Images;Classification;2009;[73][88];A. Krizhevsky et al.;
CINIC-10 Dataset;A unified contribution of CIFAR-10 and Imagenet with 10 classes, and 3 splits. Larger than CIFAR-10.;Classes labelled, training, validation, test set splits created.;270,000;Images;Classification;2018;[89];Luke N. Darlow, Elliot J. Crowley, Antreas Antoniou, Amos J. Storkey;
Fashion-MNIST;A MNIST-like fashion product database;Classes labelled, training set splits created.;60,000;Images;Classification;2017;[90];Zalando SE;
notMNIST;Some publicly available fonts and extracted glyphs from them to make a dataset similar to MNIST. There are 10 classes, with letters A-J taken from different fonts.;Classes labelled, training set splits created.;500,000;Images;Classification;2011;[91];Yaroslav Bulatov;
German Traffic Sign Detection Benchmark Dataset;Images from vehicles of traffic signs on German roads. These signs comply with UN standards and therefore are the same as in other countries.;Signs manually labeled;900;Images;Classification;2013;[92][93];S Houben et al.;
KITTI Vision Benchmark Dataset;Autonomous vehicles driving through a mid-size city captured images of various areas using cameras and laser scanners.;Many benchmarks extracted from data.;>100 GB of data;Images, text;Classification, object detection;2012;[94][95];A Geiger et al.;
Linnaeus 5 dataset;Images of 5 classes of objects.;Classes labelled, training set splits created.;8000;Images;Classification;2017;[96];Chaladze & Kalatozishvili;
FieldSAFE;Multi-modal dataset for obstacle detection in agriculture including stereo camera, thermal camera, web camera, 360-degree camera, lidar, radar, and precise localization.;Classes labelled geographically.;>400 GB of data;Images and 3D point clouds;Classification, object detection, object localization;2017;[97];M. Kragh et al.;
11K Hands;11,076 hand images (1600 x 1200 pixels) of 190 subjects, of varying ages between 18 – 75 years old, for gender recognition and biometric identification.;None;11,076 hand images;Images and (.mat, .txt, and .csv) label files;Gender recognition and biometric identification;2017;[98];M Afifi;
CORe50;Specifically designed for Continuous/Lifelong Learning and Object Recognition, is a collection of more than 500 videos (30fps) of 50 domestic objects belonging to 10 different categories.;Classes labelled, training set splits created based on a 3-way, multi-runs benchmark.;164,866 RBG-D images;images (.png or .pkl) and (.pkl, .txt, .tsv) label files;Classification, Object recognition;2017;[99];V. Lomonaco and D. Maltoni;
